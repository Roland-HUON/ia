{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7e3dcceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0305cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor([2.0], requires_grad=True)\n",
    "b = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "# Input\n",
    "x = torch.tensor([3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fcc81597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: {7.0}\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "y_pred = w * x + b\n",
    "print(\"y_pred:\", {y_pred.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "649525e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: {9.0}\n"
     ]
    }
   ],
   "source": [
    "# Loss\n",
    "y_true = torch.tensor([10.0])\n",
    "loss = (y_pred - y_true) ** 2\n",
    "print(\"Loss:\", {loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "625f0f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant backward: w.grad = None\n"
     ]
    }
   ],
   "source": [
    "print(\"Avant backward: w.grad =\", w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9e4119fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a4ff1c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après backward: w.grad = tensor([-18.])\n",
      "Apres backward: b.grad = tensor([-6.])\n"
     ]
    }
   ],
   "source": [
    "print(\"Après backward: w.grad =\", w.grad)\n",
    "print(\"Apres backward: b.grad =\", b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "62da28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "with torch.no_grad(): # Désactiver le tracking des gradients pour l'update w = w + alpha * w\n",
    "    w -= learning_rate * w.grad\n",
    "    b -= learning_rate * b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bd547104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveau poids : w = tensor([2.1800], requires_grad=True) b = tensor([1.0600], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Nouveau poids : w =\", w, \"b =\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c7cd113b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après zero_(): w.grad = tensor([0.]) b.grad = tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "# Réinitialiser les gradients\n",
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(\"Après zero_(): w.grad =\", w.grad, \"b.grad =\", b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "efea9980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poids : Parameter containing:\n",
      "tensor([[0.7008]], requires_grad=True)\n",
      "Biais : Parameter containing:\n",
      "tensor([0.7492], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "perceptron = nn.Linear(1, 1)\n",
    "\n",
    "# Voir les poids initiaux\n",
    "print(\"Poids :\", perceptron.weight)\n",
    "print(\"Biais :\", perceptron.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b2015071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : tensor([3.])\n",
      "tensor([2.8517], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Forward\n",
    "x = torch.tensor([3.0]) # Shape (batch_size, features)\n",
    "print(f\"input : {x}\")\n",
    "y_pred = perceptron(x)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7bc0fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "y_true = torch.tensor([10.0])\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4dd9f823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(51.0984, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1cdd0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7b96c6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient de poids : tensor([[-42.8899]])\n",
      "Gradient de biais : tensor([-14.2966])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient de poids : {perceptron.weight.grad}\")\n",
    "print(f\"Gradient de biais : {perceptron.bias.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c9de3438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(perceptron.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1030f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "90abcca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveau poids : Parameter containing:\n",
      "tensor([[1.1297]], requires_grad=True)\n",
      "Nouveau biais : Parameter containing:\n",
      "tensor([0.8922], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Nouveau poids :\", perceptron.weight)\n",
    "print(\"Nouveau biais :\", perceptron.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4a1c707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "87daca6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poids après zero_grad : None\n",
      "Biais après zero_grad : None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Poids après zero_grad : {perceptron.weight.grad}\")\n",
    "print(f\"Biais après zero_grad : {perceptron.bias.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "dcf98ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)\n",
    "        self.fc2 = nn.Linear(4, 3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "79448116",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d73c7957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNet(\n",
       "  (fc1): Linear(in_features=2, out_features=4, bias=True)\n",
       "  (fc2): Linear(in_features=4, out_features=3, bias=True)\n",
       "  (fc3): Linear(in_features=3, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "eae47c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0])\n",
    "y = torch.tensor([5.0])\n",
    "y_pred = model(x)\n",
    "loss = nn.MSELoss()(y_pred, y)\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d17a0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import onnxruntime as rt\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "02461311",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d7553f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_data, batch_size=64, shuffle=True, pin_memory=True, num_workers=4)\n",
    "test_data = DataLoader(test_data, batch_size=64, shuffle=False, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "315d9f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(training_data.classes)\n",
    "print(training_data.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ad10a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(64*3*3, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4bc78dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=576, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "model = CNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "cf529cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "491a756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 1, 28, 28, device=device)\n",
    "logits = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3f262e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0574, -0.0192,  0.0821, -0.0984,  0.0027, -0.1120,  0.1007, -0.0446,\n",
       "         -0.0677,  0.0264]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e065d4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1064, 0.0986, 0.1091, 0.0911, 0.1007, 0.0898, 0.1111, 0.0961, 0.0939,\n",
       "         0.1032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3cf926d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6], device='cuda:0')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pred_probab.argmax(dim=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e7dd7d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch_idx, batch_value in enumerate(dataloader):\n",
    "        X, y = batch_value\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            loss, current = loss.item(), (batch_idx+1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4b5c908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d269dfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "[Epoch 1, Batch   100] loss: 2.304\n",
      "[Epoch 1, Batch   200] loss: 2.302\n",
      "[Epoch 1, Batch   300] loss: 2.300\n",
      "[Epoch 1, Batch   400] loss: 2.300\n",
      "[Epoch 1, Batch   500] loss: 2.299\n",
      "[Epoch 1, Batch   600] loss: 2.297\n",
      "[Epoch 1, Batch   700] loss: 2.296\n",
      "[Epoch 1, Batch   800] loss: 2.294\n",
      "[Epoch 1, Batch   900] loss: 2.291\n",
      "Test Error: \n",
      " Accuracy: 31.6%, Avg loss: 2.285972 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[Epoch 2, Batch   100] loss: 2.286\n",
      "[Epoch 2, Batch   200] loss: 2.280\n",
      "[Epoch 2, Batch   300] loss: 2.270\n",
      "[Epoch 2, Batch   400] loss: 2.256\n",
      "[Epoch 2, Batch   500] loss: 2.223\n",
      "[Epoch 2, Batch   600] loss: 2.148\n",
      "[Epoch 2, Batch   700] loss: 1.974\n",
      "[Epoch 2, Batch   800] loss: 1.662\n",
      "[Epoch 2, Batch   900] loss: 1.355\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.917221 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[Epoch 3, Batch   100] loss: 1.067\n",
      "[Epoch 3, Batch   200] loss: 0.914\n",
      "[Epoch 3, Batch   300] loss: 0.834\n",
      "[Epoch 3, Batch   400] loss: 0.751\n",
      "[Epoch 3, Batch   500] loss: 0.697\n",
      "[Epoch 3, Batch   600] loss: 0.619\n",
      "[Epoch 3, Batch   700] loss: 0.561\n",
      "[Epoch 3, Batch   800] loss: 0.515\n",
      "[Epoch 3, Batch   900] loss: 0.492\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.297333 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[Epoch 4, Batch   100] loss: 0.441\n",
      "[Epoch 4, Batch   200] loss: 0.436\n",
      "[Epoch 4, Batch   300] loss: 0.379\n",
      "[Epoch 4, Batch   400] loss: 0.355\n",
      "[Epoch 4, Batch   500] loss: 0.327\n",
      "[Epoch 4, Batch   600] loss: 0.317\n",
      "[Epoch 4, Batch   700] loss: 0.337\n",
      "[Epoch 4, Batch   800] loss: 0.264\n",
      "[Epoch 4, Batch   900] loss: 0.276\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.169700 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[Epoch 5, Batch   100] loss: 0.243\n",
      "[Epoch 5, Batch   200] loss: 0.272\n",
      "[Epoch 5, Batch   300] loss: 0.238\n",
      "[Epoch 5, Batch   400] loss: 0.221\n",
      "[Epoch 5, Batch   500] loss: 0.215\n",
      "[Epoch 5, Batch   600] loss: 0.206\n",
      "[Epoch 5, Batch   700] loss: 0.211\n",
      "[Epoch 5, Batch   800] loss: 0.212\n",
      "[Epoch 5, Batch   900] loss: 0.188\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.116760 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[Epoch 6, Batch   100] loss: 0.176\n",
      "[Epoch 6, Batch   200] loss: 0.169\n",
      "[Epoch 6, Batch   300] loss: 0.175\n",
      "[Epoch 6, Batch   400] loss: 0.196\n",
      "[Epoch 6, Batch   500] loss: 0.188\n",
      "[Epoch 6, Batch   600] loss: 0.177\n",
      "[Epoch 6, Batch   700] loss: 0.172\n",
      "[Epoch 6, Batch   800] loss: 0.173\n",
      "[Epoch 6, Batch   900] loss: 0.163\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.095648 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[Epoch 7, Batch   100] loss: 0.153\n",
      "[Epoch 7, Batch   200] loss: 0.152\n",
      "[Epoch 7, Batch   300] loss: 0.147\n",
      "[Epoch 7, Batch   400] loss: 0.141\n",
      "[Epoch 7, Batch   500] loss: 0.148\n",
      "[Epoch 7, Batch   600] loss: 0.147\n",
      "[Epoch 7, Batch   700] loss: 0.143\n",
      "[Epoch 7, Batch   800] loss: 0.146\n",
      "[Epoch 7, Batch   900] loss: 0.137\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.075188 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[Epoch 8, Batch   100] loss: 0.137\n",
      "[Epoch 8, Batch   200] loss: 0.143\n",
      "[Epoch 8, Batch   300] loss: 0.134\n",
      "[Epoch 8, Batch   400] loss: 0.120\n",
      "[Epoch 8, Batch   500] loss: 0.125\n",
      "[Epoch 8, Batch   600] loss: 0.117\n",
      "[Epoch 8, Batch   700] loss: 0.106\n",
      "[Epoch 8, Batch   800] loss: 0.137\n",
      "[Epoch 8, Batch   900] loss: 0.121\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.069148 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[Epoch 9, Batch   100] loss: 0.116\n",
      "[Epoch 9, Batch   200] loss: 0.118\n",
      "[Epoch 9, Batch   300] loss: 0.125\n",
      "[Epoch 9, Batch   400] loss: 0.118\n",
      "[Epoch 9, Batch   500] loss: 0.120\n",
      "[Epoch 9, Batch   600] loss: 0.117\n",
      "[Epoch 9, Batch   700] loss: 0.110\n",
      "[Epoch 9, Batch   800] loss: 0.114\n",
      "[Epoch 9, Batch   900] loss: 0.112\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.064401 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[Epoch 10, Batch   100] loss: 0.121\n",
      "[Epoch 10, Batch   200] loss: 0.101\n",
      "[Epoch 10, Batch   300] loss: 0.105\n",
      "[Epoch 10, Batch   400] loss: 0.110\n",
      "[Epoch 10, Batch   500] loss: 0.123\n",
      "[Epoch 10, Batch   600] loss: 0.103\n",
      "[Epoch 10, Batch   700] loss: 0.112\n",
      "[Epoch 10, Batch   800] loss: 0.109\n",
      "[Epoch 10, Batch   900] loss: 0.100\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.054261 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    for i, data in enumerate(training_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f'[Epoch {t + 1}, Batch {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "        \n",
    "    # train(training_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_data, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d71a88e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `CNN([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `CNN([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n"
     ]
    }
   ],
   "source": [
    "example_input = (torch.randn(1, 1, 28, 28),)\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "onnx_program = torch.onnx.export(model, example_input, input_names=[\"input\"], output_names=[\"output\"], dynamo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8c664365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-4.4135857 , -1.0919702 ,  1.0299526 ,  6.5817504 , -5.1239715 ,\n",
      "         5.4989266 , -3.1605928 , -0.17881511,  3.6822152 , -0.38163128]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "onnx_program.save(\"model.onnx\")\n",
    "sess = rt.InferenceSession(\"model.onnx\", providers= rt.get_available_providers())\n",
    "input_name = sess.get_inputs()[0].name\n",
    "pred_onnx = sess.run(None, {input_name: example_input[0].numpy()})\n",
    "print(pred_onnx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
