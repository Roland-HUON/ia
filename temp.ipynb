{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7e3dcceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0305cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor([2.0], requires_grad=True)\n",
    "b = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "# Input\n",
    "x = torch.tensor([3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fcc81597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: {7.0}\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "y_pred = w * x + b\n",
    "print(\"y_pred:\", {y_pred.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "649525e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: {9.0}\n"
     ]
    }
   ],
   "source": [
    "# Loss\n",
    "y_true = torch.tensor([10.0])\n",
    "loss = (y_pred - y_true) ** 2\n",
    "print(\"Loss:\", {loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "625f0f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant backward: w.grad = None\n"
     ]
    }
   ],
   "source": [
    "print(\"Avant backward: w.grad =\", w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9e4119fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a4ff1c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après backward: w.grad = tensor([-18.])\n",
      "Apres backward: b.grad = tensor([-6.])\n"
     ]
    }
   ],
   "source": [
    "print(\"Après backward: w.grad =\", w.grad)\n",
    "print(\"Apres backward: b.grad =\", b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "62da28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "with torch.no_grad(): # Désactiver le tracking des gradients pour l'update w = w + alpha * w\n",
    "    w -= learning_rate * w.grad\n",
    "    b -= learning_rate * b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bd547104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveau poids : w = tensor([2.1800], requires_grad=True) b = tensor([1.0600], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Nouveau poids : w =\", w, \"b =\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c7cd113b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après zero_(): w.grad = tensor([0.]) b.grad = tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "# Réinitialiser les gradients\n",
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(\"Après zero_(): w.grad =\", w.grad, \"b.grad =\", b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "efea9980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poids : Parameter containing:\n",
      "tensor([[-0.2722]], requires_grad=True)\n",
      "Biais : Parameter containing:\n",
      "tensor([-0.3021], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "perceptron = nn.Linear(1, 1)\n",
    "\n",
    "# Voir les poids initiaux\n",
    "print(\"Poids :\", perceptron.weight)\n",
    "print(\"Biais :\", perceptron.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b2015071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : tensor([3.])\n",
      "tensor([-1.1188], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Forward\n",
    "x = torch.tensor([3.0]) # Shape (batch_size, features)\n",
    "print(f\"input : {x}\")\n",
    "y_pred = perceptron(x)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7bc0fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "y_true = torch.tensor([10.0])\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4dd9f823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(123.6270, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1cdd0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7b96c6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient de poids : tensor([[-66.7126]])\n",
      "Gradient de biais : tensor([-22.2375])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient de poids : {perceptron.weight.grad}\")\n",
    "print(f\"Gradient de biais : {perceptron.bias.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c9de3438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(perceptron.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1030f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "90abcca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveau poids : Parameter containing:\n",
      "tensor([[0.3949]], requires_grad=True)\n",
      "Nouveau biais : Parameter containing:\n",
      "tensor([-0.0797], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Nouveau poids :\", perceptron.weight)\n",
    "print(\"Nouveau biais :\", perceptron.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4a1c707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "87daca6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poids après zero_grad : None\n",
      "Biais après zero_grad : None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Poids après zero_grad : {perceptron.weight.grad}\")\n",
    "print(f\"Biais après zero_grad : {perceptron.bias.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dcf98ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)\n",
    "        self.fc2 = nn.Linear(4, 3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "79448116",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d73c7957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNet(\n",
       "  (fc1): Linear(in_features=2, out_features=4, bias=True)\n",
       "  (fc2): Linear(in_features=4, out_features=3, bias=True)\n",
       "  (fc3): Linear(in_features=3, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eae47c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0])\n",
    "y = torch.tensor([5.0])\n",
    "y_pred = model(x)\n",
    "loss = nn.MSELoss()(y_pred, y)\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d17a0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import onnxruntime as rt\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "02461311",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d7553f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_data, batch_size=64, shuffle=True, pin_memory=True, num_workers=4)\n",
    "test_data = DataLoader(test_data, batch_size=64, shuffle=False, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "315d9f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(training_data.classes)\n",
    "print(training_data.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ad10a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4bc78dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "491a756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3f262e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0369,  0.0068, -0.0701,  0.0135, -0.1061, -0.0629,  0.0459,  0.0253,\n",
       "         -0.0087,  0.1294]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e065d4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0968, 0.1011, 0.0936, 0.1018, 0.0903, 0.0943, 0.1051, 0.1030, 0.0996,\n",
       "         0.1143]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3cf926d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9], device='cuda:0')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pred_probab.argmax(dim=1)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cf529cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e7dd7d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch_idx, batch_value in enumerate(dataloader):\n",
    "        X, y = batch_value\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            loss, current = loss.item(), (batch_idx+1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4b5c908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d269dfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.303890  [   64/60000]\n",
      "loss: 2.293590  [ 6464/60000]\n",
      "loss: 2.291224  [12864/60000]\n",
      "loss: 2.284647  [19264/60000]\n",
      "loss: 2.281651  [25664/60000]\n",
      "loss: 2.286632  [32064/60000]\n",
      "loss: 2.272811  [38464/60000]\n",
      "loss: 2.279360  [44864/60000]\n",
      "loss: 2.261609  [51264/60000]\n",
      "loss: 2.263924  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 36.5%, Avg loss: 2.258961 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.268828  [   64/60000]\n",
      "loss: 2.249856  [ 6464/60000]\n",
      "loss: 2.251795  [12864/60000]\n",
      "loss: 2.256744  [19264/60000]\n",
      "loss: 2.237898  [25664/60000]\n",
      "loss: 2.239049  [32064/60000]\n",
      "loss: 2.239892  [38464/60000]\n",
      "loss: 2.215648  [44864/60000]\n",
      "loss: 2.225399  [51264/60000]\n",
      "loss: 2.207261  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 2.195612 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.198908  [   64/60000]\n",
      "loss: 2.206436  [ 6464/60000]\n",
      "loss: 2.190112  [12864/60000]\n",
      "loss: 2.181303  [19264/60000]\n",
      "loss: 2.181831  [25664/60000]\n",
      "loss: 2.154043  [32064/60000]\n",
      "loss: 2.135504  [38464/60000]\n",
      "loss: 2.137768  [44864/60000]\n",
      "loss: 2.118694  [51264/60000]\n",
      "loss: 2.093813  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 2.091169 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.075872  [   64/60000]\n",
      "loss: 2.122307  [ 6464/60000]\n",
      "loss: 2.065805  [12864/60000]\n",
      "loss: 2.087851  [19264/60000]\n",
      "loss: 2.007452  [25664/60000]\n",
      "loss: 2.004425  [32064/60000]\n",
      "loss: 2.004416  [38464/60000]\n",
      "loss: 1.967321  [44864/60000]\n",
      "loss: 1.952167  [51264/60000]\n",
      "loss: 1.954882  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 1.915387 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.903078  [   64/60000]\n",
      "loss: 1.914860  [ 6464/60000]\n",
      "loss: 1.886066  [12864/60000]\n",
      "loss: 1.853578  [19264/60000]\n",
      "loss: 1.816030  [25664/60000]\n",
      "loss: 1.772515  [32064/60000]\n",
      "loss: 1.719512  [38464/60000]\n",
      "loss: 1.776472  [44864/60000]\n",
      "loss: 1.707164  [51264/60000]\n",
      "loss: 1.642284  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 1.646632 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.679356  [   64/60000]\n",
      "loss: 1.656199  [ 6464/60000]\n",
      "loss: 1.719154  [12864/60000]\n",
      "loss: 1.547009  [19264/60000]\n",
      "loss: 1.440996  [25664/60000]\n",
      "loss: 1.525927  [32064/60000]\n",
      "loss: 1.416067  [38464/60000]\n",
      "loss: 1.415305  [44864/60000]\n",
      "loss: 1.454434  [51264/60000]\n",
      "loss: 1.250148  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 1.330177 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.249797  [   64/60000]\n",
      "loss: 1.324455  [ 6464/60000]\n",
      "loss: 1.304992  [12864/60000]\n",
      "loss: 1.158637  [19264/60000]\n",
      "loss: 1.131506  [25664/60000]\n",
      "loss: 1.171403  [32064/60000]\n",
      "loss: 1.143109  [38464/60000]\n",
      "loss: 1.135563  [44864/60000]\n",
      "loss: 1.284407  [51264/60000]\n",
      "loss: 1.111659  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 1.061110 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.980312  [   64/60000]\n",
      "loss: 1.061277  [ 6464/60000]\n",
      "loss: 0.930753  [12864/60000]\n",
      "loss: 1.083815  [19264/60000]\n",
      "loss: 1.140218  [25664/60000]\n",
      "loss: 1.009910  [32064/60000]\n",
      "loss: 0.859228  [38464/60000]\n",
      "loss: 0.908849  [44864/60000]\n",
      "loss: 0.922459  [51264/60000]\n",
      "loss: 0.813084  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.875053 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.907645  [   64/60000]\n",
      "loss: 0.911606  [ 6464/60000]\n",
      "loss: 0.880953  [12864/60000]\n",
      "loss: 0.741440  [19264/60000]\n",
      "loss: 0.792272  [25664/60000]\n",
      "loss: 0.886173  [32064/60000]\n",
      "loss: 0.935496  [38464/60000]\n",
      "loss: 0.863520  [44864/60000]\n",
      "loss: 0.744487  [51264/60000]\n",
      "loss: 0.677958  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.751437 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.801298  [   64/60000]\n",
      "loss: 0.807652  [ 6464/60000]\n",
      "loss: 0.695710  [12864/60000]\n",
      "loss: 0.700873  [19264/60000]\n",
      "loss: 0.743127  [25664/60000]\n",
      "loss: 0.580536  [32064/60000]\n",
      "loss: 0.819552  [38464/60000]\n",
      "loss: 0.842576  [44864/60000]\n",
      "loss: 0.709762  [51264/60000]\n",
      "loss: 0.769599  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.666379 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(training_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_data, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d71a88e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `NeuralNetwork([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `NeuralNetwork([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n"
     ]
    }
   ],
   "source": [
    "example_input = (torch.randn(1, 1, 28, 28),)\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "onnx_program = torch.onnx.export(model, example_input, input_names=[\"input\"], output_names=[\"output\"], dynamo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8c664365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.2821919 , -1.2141246 , -1.3455317 , -0.04980967,  0.9074416 ,\n",
      "         0.41972417, -0.80220217,  2.288466  , -0.41802472,  1.4256362 ]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "onnx_program.save(\"model.onnx\")\n",
    "sess = rt.InferenceSession(\"model.onnx\", providers= rt.get_available_providers())\n",
    "input_name = sess.get_inputs()[0].name\n",
    "pred_onnx = sess.run(None, {input_name: example_input[0].numpy()})\n",
    "print(pred_onnx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
